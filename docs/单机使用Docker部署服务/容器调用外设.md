# 容器调用外设

通常我们不用docker部署那些需要访问外部挂载外设的服务,不过并不是不能.

容器中使用外设可以分为两种:

1. 容器访问外设,典型的就是调用usb摄像头,调用扩音器等.这种方式通过`devices`字段挂载.我们以调用usb摄像头为例
2. 容器访问gpu.这种只能通过设置docker配置中的`runtimes`配合专用的基镜像来使用

## 调用usb摄像头

容器调用摄像头的前提是宿主机上有usb摄像头.

为了验证我们的宿主机上usb摄像头已经安装完成我们需要ssh可以看远程机器上传过来的视频信号

### usb设备机器上的准备工作

1. 在服务器端配置`/etc/ssh/sshd_config`

    ```txt
    X11Forwarding yes
    X11DisplayOffset 10
    PrintMotd no
    PrintLastLog yes
    TCPKeepAlive yes
    ```

### mac上的准备工作

1. 安装[libsdl](http://www.libsdl.org/download-2.0.php),下载好后按readme中写的方式将文件夹`SDL2.framework`放入`/Library/Frameworks`
2. 安装[xquartz](https://www.xquartz.org/)下载好后双击安装
3. 打开`xquartz`

### 验证摄像头可用

通过`xquartz`的terminal我们用ssh访问挂着摄像头的宿主机,之后:

1. 查看摄像头路径`ls /dev/video*`我们可以看到摄像头路径为`/dev/video0`
2. 查看usb设备信息`lsusb`
3. 安装camorama,`sudo apt-get install camorama`
4. 执行`camorama -d /dev/video0`我们就可以在自己的机器上通过摄像头挂载的宿主机看到摄像头捕获的视频了

### 容器挂载摄像头

我们使用如下compose文件部署一个debian的镜像

+ dockerfile

    ```dockerfile
    FROM --platform=${TARGETPLATFORM} debian:buster-slim
    CMD [ "ls", "/dev" ]
    ```

+ `docker-compose.yml`

    ```yml
    version: "2.4"

    x-log: &default-log
    options:
        max-size: "10m"
        max-file: "3"

    services:
    hello-video:
        image: hsz1273327/hello-video:0.0.1
        cpus: 0.8
        mem_limit: 100m
        memswap_limit: 200m
        restart: on-failure
        logging:
        <<: *default-log
        devices:
        - "/dev/video0:/dev/video0"
        privileged: true
    
    ```

## docker容器调用gpu

docker容器中调用gpu分几种情况:

1. 在linux下使用原生的docker.

2. 在windows下使用docker desktop.

mac下因为本来就没有nvidia显卡,所以也就不存在调用gpu的可能了.

### 在linux下使用原生的docker

这种情况下docker直接在操作系统中,相对会比较容易使用gpu.在`docker 19.03`之前如果我们想使用gpu,那么我们必须使用`nvidia-docker`这个docker的实现,而在之后docker已经原生支持gpu了,我们可以声明`nvidia-container-runtime`的位置来直接支持使用gpu.本文以`docker 19.03`以后的版本为准,因此就不介绍`nvidia-docker`了.

#### 准备工作

1. 安装[`nvidia`驱动](https://www.nvidia.com/Download/index.aspx)
2. 安装`nvidia-container-runtime`,`apt-get install nvidia-container-runtime`

如果我们使用的是`jetson`系列的开发板,安装对应版本的`ubuntu`会自带上面的组件.

我用的是[jetson-nano](https://developer.nvidia.com/zh-cn/embedded/learn/get-started-jetson-nano-devkit)来做例子.

通过使用`nvidia-smi`查看gpu状态
使用`jtop`(`pip3 install jetson-stats`)查看gpu使用情况

#### 专用基镜像

nvidia提供了几个`jetson`专用基镜像(https://developer.nvidia.com/embedded/jetson-cloud-native),下面是简介:

+ [L4T-Base Container](https://ngc.nvidia.com/catalog/containers/nvidia:l4t-base)CUDA,cuDNN,TensorRT的运行环境
+ [DeepStream Container](https://ngc.nvidia.com/catalog/containers/nvidia:deepstream-l4t)CUDA,cuDNN,TensorRT和DeepStream的运行环境
+ [l4t-tensorflow](https://ngc.nvidia.com/catalog/containers/nvidia:l4t-tensorflow)有gpu版本tensorflow(最高tf2.3,python3.6)的运行环境
+ [l4t-pytorch](https://ngc.nvidia.com/catalog/containers/nvidia:l4t-pytorch)有gpu版本pytorch(最高pytorch1.7,python3.6)的运行环境
+ [l4t-ml](https://ngc.nvidia.com/catalog/containers/nvidia:l4t-ml)含TensorFlow,PyTorch, JupyterLab,pandas等最常见机器学习工具的运行环境

除此之外dockerhub上还有一个[常用三方镜像集合](https://hub.docker.com/u/helmuthva)

如果不是使用的jetson开发板,可以使用官方的[cuda镜像](https://hub.docker.com/r/nvidia/cuda)

#### 调用gpu

要调用gpu首先要在配置中声明好runtime:

```json
{
    ...
    "runtimes": {
        ...
        "nvidia": {
            "path": "nvidia-container-runtime",
            "runtimeArgs": []
        }
    },

}
```

使用docker compose调用gpu具体的可以看[官方文档](https://docs.docker.com/compose/gpu-support/).在2.4版本中只要申明`runtime: nvidia`就可以.

我们现在尝试使用一下:

+ docker-compose.yaml

    ```yaml
    version: "2.4"

    x-log: &default-log
    options:
        max-size: "10m"
        max-file: "3"

    services:
    hello-jetson:
        image: nvcr.io/nvidia/l4t-tensorflow:r32.5.0-tf2.3-py3
        runtime: nvidia
        cpus: 0.8
        mem_limit: 100m
        memswap_limit: 200m
        restart: on-failure
        logging:
        <<: *default-log
        command: 
        - python3
        - -c
        - "import tensorflow as tf;print(tf.config.list_physical_devices('GPU'));"
    ```

运行完成后他会打印出当前的gpu名列表.

### 在windows下使用docker desktop在容器中调用gpu

在windows下使用docker desktop在容器中调用gpu需要满足如下要求

1. 有NVIDIA的gpu
2. Windows更新到最新版本并且使用预览版windows10(参加`Windows Insider Program`)
3. 更新[nvidia驱动](https://developer.nvidia.com/cuda/wsl/download)(注意需要注册账号)
4. 更新wsl2到最新(可以去<https://www.catalog.update.microsoft.com/Search.aspx?q=wsl>查看更新和下载,可以在wls2所在的linux中使用`uname -a`查看当前版本),如果你是win10预览版用户,可以直接使用`wsl --update`更新;如果无法使用则只能去刚才的位置下载最新版本后按如下步骤更新
   1. 彻底关闭当前的 WSL(以管理员身份运行`wsl --shutdown`)
   2. 解压下载好的`wsl_update_x64_xxxxx.cab`后得到`wsl_update_x64.msi`文件,运行完成内核更新


