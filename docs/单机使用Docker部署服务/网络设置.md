# 网络设置

通常我们的服务都是为了让外部访问的,在上面的例子中我们虽然将服务启动了但外部并没有办法访问.本文将介绍单机环境下的Docker网络配置.

Docker中网络配置是专门的一块.在创建stack的时候我们可以指定stack专用的网络,也可以使用`docker networks`子命令管理和创建用户自定义的网络对象.

单机条件下可用的网络驱动有两种:

+ `bridge`也就是桥接网络,也是docker容器在单机环境下的默认网络类型.大致会损失20%的io性能
+ `host`也就是完全映射宿主机的网络,几乎无io性能损失
+ `none`关闭容器的网络功能

## bridge网络

`bridge`驱动会为每一个容器分配,设置IP等网络相关资源,并将容器连接到一个`docker0`虚拟网桥.通过`docker0`网桥以及`Iptables nat表`配置与宿主机以及其他容器通信.

`bridge`网络的例子在[example-standalone-network-bridge](https://github.com/hsz1273327/TutorialForDocker/tree/example-standalone-network-bridge)

### 与宿主机通信

与宿主机通信可以分为两段:

1. 宿主机访问服务的端口
2. 服务中的容器访问宿主机上的端口

#### 宿主机访问服务

`bridge`网络模式通过设置`ports`字段声明对外暴露的端口,其形式为`HOST:CONTAINER`:

```yml
ports:
  - "3000" # 容器的3000端口映射到宿主机的一个随机端口
  - "5000:4000" # 容器的4000端口映射为宿主机的5000端口
  - "6060:6050/udp" # 容器udp网络协议的6050端口映射为宿主机的6060端口
```

需要注意.定义`ports`的服务下必须只有一个容器,否则将只能启动一个容器,其他容器会报端口占用错误.因此一般申明`ports`的服务会是一个负载均衡器

#### 容器访问宿主机

容器要访问宿主机上的端口根据不同的安装环境有两种方式:

+ 如果是windows或者mac平台使用的`docker desktop`运行的docker服务,那么可以在容器种使用`host.docker.internal`作为hostname代表宿主机.
+ 如果是linux下直接安装的docker,则可以直接使用本机的内网ip作为hostname在容器种使用.

我们在`app.py`的代码中通过获取环境变量`REDIS_URL`来这是连接的redis的路径.在`docker-compose.yml`中我们则是通过`environment`字段来设置环境变量`REDIS_URL`的值.

我们使用`host.docker.internal`指代宿主机的hostname,这样就可以访问到redis了.

本例中我们将`db-redis`的端口暴露给了宿主机的`16379`端口.因此,如果我们是在windows或mac上运行示例,我们只要修改环境变量`HELLO_DOCKER_REDIS_URL`为`redis://host.docker.internal:16379?db=0`就是连接到宿主机.如果是在linux上运行示例,则我们修改环境变量`HELLO_DOCKER_REDIS_URL`为`redis://<宿主机ip>:16379?db=0`就是连接到宿主机.

### 容器间互联

容器间互联可以分为相同服务栈内容器的互联和不同服务栈内容器的互联.

#### 相同服务栈内容器的互联

单机情况下我们部署服务栈时会默认创建一个名为`<服务栈名>_default`的bridge网络.我们也可以在服务栈中使用`networks`来申明一个bridge网络,然后在需要的服务中使用它.

在我们的程序中,只需要将hostname设置为同服务栈下的服务名即可.在本例中,我们修改环境变量`HELLO_DOCKER_REDIS_URL`为`redis://db-redis?db=0`就是连接到同服务栈内的容器

#### 不同服务栈内容器的互联

不在同一服务栈内的容器互联就需要使用可依附的网络对象了.我们需要先创建一个可依附的用户自定义网络对象,然后将两个需要关联的服务连接起来.

+ 创建网络对象`attached_bridge_net`

```bash
docker network create \
--driver bridge \
--attachable \
attached_bridge_net
```

我们选择`bridge`类型的网络,然后设置`--attachable`让容器可以访问它.

+ 创建一个依附于网络`attached_bridge_net`的容器

```bash
docker run -d --name=outside_redis --network=attached_bridge_net redis
```

+ 在服务栈中声明`attached_redis_net`网络,并让服务`hellodocker`与之关联

```yaml
...
services:
  ...
  hellodocker:
    ...
    networks:
      - attached_bridge_net
      ...
networks:
  attached_bridge_net:
    external: true
  ...

```

bridge网络支持服务同时连接复数个bridge网络.服务会在其中寻找符合要求的域名.我们就可以直接使用容器名访问容器了.

如果我们的自定义网络只是内部通信使用不用对外暴露,可以在创建网络时指定`--internal`.

#### 网络对象的管理

像上面的例子种一样,我们用`docker network`子命令管理网络对象

| 命令                                                    | 说明                                                                                           |
| ------------------------------------------------------- | ---------------------------------------------------------------------------------------------- |
| `docker network create [OPTIONS] NETWORK`               | 创建网络,使用`--driver`指定类型,`--attachable`指定是否可以添加容器进去,`--scope`指定作用域范围 |
| `docker network inspect [OPTIONS] NETWORK [NETWORK...]` | 观测指定网络配置和状态                                                                         |
| `docker network ls [OPTIONS]`                           | 查看所有网络对象,`--no-trunc`可以展示网络对象的完整id                                          |
| `docker network rm NETWORK [NETWORK...]`                | 删除指定网络对象                                                                               |
| `docker network prune [OPTIONS]`                        | 删除所有不在使用的网络对象,`-f`可以跳过询问                                                    |

## host网络

单机下最方便的就是使用`host`网络,它会像在本地开发一样的和宿主机共享网络端口,其配置方法就是在`run`命令中指定`--net=host`或者在`compose`文件中的`service`中使用`network_mode`声明使用`host`网络:

```yml
...
services:
  ...
  hellodocker:
    ...
    network_mode: "host"
      ...
...
```

这种方式性能几乎不会有损失.同时由于是直接使用宿主机的网络,所以容器中暴露的端口会直接在宿主机上绑定,服务的容器量就只能设置为1个了否则会有端口冲突.

需要注意由于`docker desktop`的实现问题,在windows和mac下这个方式并不会起任何效果,也就是说只在linux下会生效.由于多数人还是在windows/mac下做开发,因此这种方式其实对于开发来说实用性不高.但由于性能无损失,实际上这种方式在低性能机器上反而实用.

注意:**如果指定为host驱动,服务栈就无法再指定其他网络了,包括networks和ports**

## 为容器指定hosts配置

我们可以通过参数``人为的将hosts列表传入我们的容器内.

```yaml
...
services:
  ...
  hellodocker:
    ...
    extra_hosts:
      - "somehost:162.242.195.82"
      - "otherhost:50.31.209.229"
      ...
...
```

这个配置会在容器的`/etc/hosts`中创建一个包含ip地址和主机名的条目.
这个例子在[example-standalone-network-host](https://github.com/hsz1273327/TutorialForDocker/tree/example-standalone-network-host)

## 单机条件下网络性能对比

测试条件:

+ docker环境:[jetson Nano](https://www.nvidia.cn/autonomous-machines/embedded-systems/jetson-nano/)使用供电接口而非usb方式启动.
+ 网络环境: 家庭用内网千兆网口使用六类网线走交换机连接
+ 外部请求环境: cpu-j1900,内存8g家用nas

测试工具:

+ [iperf](https://iperf.fr/iperf-download.php)

测试代码在[example-standalone-network-benchmark](https://github.com/hsz1273327/TutorialForDocker/tree/example-standalone-network-benchmark)

本测试使用十个线程并行测试,结果如下:

+ 单机内部通信
  
| 测试位置 | 服务端driver | 客户端driver | 服务端吞吐量(GBytes) | 客户端吞吐量(GBytes) | 服务端比特率(Gbits/s) | 客户端比特率(Gbits/s) |
| -------- | ------------ | ------------ | -------------------- | -------------------- | --------------------- | --------------------- |
| 同机访问 | host         | host         | 14.5                 | 14.5                 | 12.5                  | 12.5                  |
| 同机访问 | host         | bridge       | 11.7                 | 11.7                 | 10.0                  | 10.0                  |
| 同机访问 | bridge       | host         | 11.3                 | 11.3                 | 9.71                  | 9.72                  |
| 同机访问 | bridge       | bridge       | 11.1                 | 11.1                 | 9.54                  | 9.54                  |

可以认为,以服务客户端都为host模式作为标准,可以得到如下结论:

| 测试位置 | 服务端driver | 客户端driver | 服务端吞吐量比例 | 客户端吞吐量比例 | 服务端比特率比例 | 客户端比特率比例 |
| -------- | ------------ | ------------ | ---------------- | ---------------- | ---------------- | ---------------- |
| 同机访问 | host         | host         | 1.0              | 1.0              | 1.0              | 1.0              |
| 同机访问 | host         | bridge       | 0.807            | 0.807            | 0.8              | 0.8              |
| 同机访问 | bridge       | host         | 0.779            | 0.779            | 0.777            | 0.778            |
| 同机访问 | bridge       | bridge       | 0.766            | 0.766            | 0.763            | 0.763            |

+ 千兆局域网内部通信

| 测试位置         | 服务端driver | 客户端driver | 服务端吞吐量(GBytes) | 客户端吞吐量(GBytes) | 服务端比特率(Mbits/s) | 客户端比特率(Mbits/s) |
| ---------------- | ------------ | ------------ | -------------------- | -------------------- | --------------------- | --------------------- |
| 千兆局域网内访问 | host         | host         | 1.10                 | 1.10                 | 939                   | 948                   |
| 千兆局域网内访问 | host         | bridge       | 1.10                 | 1.12                 | 937                   | 962                   |
| 千兆局域网内访问 | bridge       | host         | 1.10                 | 1.10                 | 938                   | 948                   |
| 千兆局域网内访问 | bridge       | bridge       | 1.10                 | 1.12                 | 938                   | 965                   |

### 结论

在不考虑内网网络带宽的情况下bridge模式的性能总体上来说是host模式的75%到80%,但在千兆网条件下host模式的网络性能和bridge模式没有本质区别,都受限于网络带宽,甚至客户端性能还略好于host模式.
